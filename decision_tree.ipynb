{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree: Exercises\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports:\n",
    "\n",
    "# Standard DS imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# acquisition:\n",
    "from pydataset import data\n",
    "import acquire\n",
    "\n",
    "# prep\n",
    "import prepare\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# stats\n",
    "from scipy import stats\n",
    "\n",
    "# read_csv\n",
    "import os\n",
    "\n",
    "# Modeling\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier as DT, plot_tree, export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquire data\n",
    "df = acquire.get_titanic_data('titanic_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "df = prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             891 non-null    int64  \n",
      " 1   survived                 891 non-null    int64  \n",
      " 2   pclass                   891 non-null    int64  \n",
      " 3   sex                      891 non-null    object \n",
      " 4   sibsp                    891 non-null    int64  \n",
      " 5   parch                    891 non-null    int64  \n",
      " 6   fare                     891 non-null    float64\n",
      " 7   embark_town              891 non-null    object \n",
      " 8   alone                    891 non-null    int64  \n",
      " 9   sex_male                 891 non-null    int64  \n",
      " 10  embark_town_Queenstown   891 non-null    int64  \n",
      " 11  embark_town_Southampton  891 non-null    int64  \n",
      "dtypes: float64(1), int64(9), object(2)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['sex','embark_town', 'passenger_id', 'sibsp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 8)\n",
      "\n",
      "Train: (534, 8)\n",
      "Validate: (178, 8)\n",
      "Test: (179, 8)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "train_titanic, validate_titanic, test_titanic = prepare.split_function(df, 'survived')\n",
    "print(f'Prepared df: {df.shape}')\n",
    "print()\n",
    "print(f'Train: {train_titanic.shape}')\n",
    "print(f'Validate: {validate_titanic.shape}')\n",
    "print(f'Test: {test_titanic.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. What is your baseline prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    329\n",
       "1    205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most common value is the encoded value '0', or \"Did not survive\"\n",
    "train_titanic.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. What is your baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is 61.61%\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = (train_titanic.survived == 0).mean()\n",
    "print(f'Baseline accuracy is{baseline_accuracy: .2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split Train, validate, test into x and y:\n",
    "# x and y for Training Set\n",
    "x_train = train_titanic.drop(columns=['survived'])\n",
    "y_train = train_titanic['survived']\n",
    "\n",
    "# x and y for Validate Set\n",
    "x_validate = validate_titanic.drop(columns=['survived'])\n",
    "y_validate = validate_titanic['survived']\n",
    "\n",
    "# x and y for Test Set\n",
    "x_test = test_titanic.drop(columns=['survived'])\n",
    "y_test = test_titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CREATE OBJECT:\n",
    "clf = DT(random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=666)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=666)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=666)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. FIT OBJECT\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model,x,y):\n",
    "    \n",
    "    labels = sorted(y_train.unique())\n",
    "\n",
    "    # OUTPUTS AN ARRAY OF PREDICTIONS\n",
    "    preds = clf.predict(x)\n",
    "    print(\"Accuracy Score:\", model.score(x,y))\n",
    "    print()\n",
    "    print('Confusion Matrix:')\n",
    "    conf = confusion_matrix(y,preds)\n",
    "    conf = pd.DataFrame(conf,\n",
    "            index=[str(label) + '_actual'for label in labels],\n",
    "            columns=[str(label) + '_predict'for label in labels])\n",
    "    print(conf)\n",
    "    print()\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9438202247191011\n",
      "\n",
      "Confusion Matrix:\n",
      "          0_predict  1_predict\n",
      "0_actual        327          2\n",
      "1_actual         28        177\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       329\n",
      "           1       0.99      0.86      0.92       205\n",
      "\n",
      "    accuracy                           0.94       534\n",
      "   macro avg       0.95      0.93      0.94       534\n",
      "weighted avg       0.95      0.94      0.94       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Sample results from get_metrics()\n",
    "get_metrics(clf,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "**ANSWER: Accuracy: 79.21%; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(TN,FP,FN,TP):\n",
    "    all_ = (TP + TN + FP + FN)\n",
    "\n",
    "    accuracy = (TP + TN) / all_\n",
    "\n",
    "    TPR = recall = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    TNR = TN / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "\n",
    "    precision =  TP / (TP + FP)\n",
    "    f1 =  2 * ((precision * recall) / ( precision + recall))\n",
    "\n",
    "    support_pos = TP + FN\n",
    "    support_neg = FP + TN\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    print(f\"True Positive Rate/Sensitivity/Recall/Power: {TPR}\")\n",
    "    print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {FPR}\")\n",
    "    print(f\"True Negative Rate/Specificity/Selectivity: {TNR}\")\n",
    "    print(f\"False Negative Rate/Miss Rate: {FNR}\\n\")\n",
    "    print(f\"Precision/PPV: {precision}\")\n",
    "    print(f\"F1 Score: {f1}\\n\")\n",
    "    print(f\"Support (0): {support_pos}\")\n",
    "    print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 2, 28, 177)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confu = confusion_matrix(y_train,clf.predict(x_train))\n",
    "TN, FP, FN, TP = confu.ravel()\n",
    "TN, FP, FN, TP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9438202247191011\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.8634146341463415\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.0060790273556231\n",
      "True Negative Rate/Specificity/Selectivity: 0.993920972644377\n",
      "False Negative Rate/Miss Rate: 0.13658536585365855\n",
      "\n",
      "Precision/PPV: 0.9888268156424581\n",
      "F1 Score: 0.921875\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, f1-score, and support: Use classification_report\n",
    "compute_metrics(TN,FP,FN,TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921348314606742"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Model\n",
    "clf_2=DT(max_depth=2, random_state=666)\n",
    "clf_2.fit(x_train, y_train)\n",
    "clf_2.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7921348314606742\n",
      "\n",
      "Confusion Matrix:\n",
      "          0_predict  1_predict\n",
      "0_actual        327          2\n",
      "1_actual         28        177\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       329\n",
      "           1       0.99      0.86      0.92       205\n",
      "\n",
      "    accuracy                           0.94       534\n",
      "   macro avg       0.95      0.93      0.94       534\n",
      "weighted avg       0.95      0.94      0.94       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Eval\n",
    "get_metrics(clf_2, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 46, 65, 140)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Compute\n",
    "confu = confusion_matrix(y_train,clf_2.predict(x_train))\n",
    "TN, FP, FN, TP = confu.ravel()\n",
    "TN, FP, FN, TP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7921348314606742\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6829268292682927\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.1398176291793313\n",
      "True Negative Rate/Specificity/Selectivity: 0.8601823708206687\n",
      "False Negative Rate/Miss Rate: 0.3170731707317073\n",
      "\n",
      "Precision/PPV: 0.7526881720430108\n",
      "F1 Score: 0.7161125319693095\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(TN,FP,FN,TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.79\n",
      "for depth of  2, the accuracy is 0.79\n",
      "for depth of  3, the accuracy is 0.82\n",
      "for depth of  4, the accuracy is 0.82\n",
      "for depth of  5, the accuracy is 0.83\n",
      "for depth of  6, the accuracy is 0.87\n",
      "for depth of  7, the accuracy is 0.88\n",
      "for depth of  8, the accuracy is 0.9\n",
      "for depth of  9, the accuracy is 0.92\n",
      "for depth of 10, the accuracy is 0.92\n",
      "for depth of 11, the accuracy is 0.93\n",
      "for depth of 12, the accuracy is 0.94\n",
      "for depth of 13, the accuracy is 0.94\n",
      "for depth of 14, the accuracy is 0.94\n",
      "for depth of 15, the accuracy is 0.94\n",
      "for depth of 16, the accuracy is 0.94\n",
      "for depth of 17, the accuracy is 0.94\n",
      "for depth of 18, the accuracy is 0.94\n",
      "for depth of 19, the accuracy is 0.94\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,20):\n",
    "    tree = DT(max_depth=x, random_state=666)\n",
    "    tree.fit(x_train, y_train)\n",
    "    acc = tree.score(x_train, y_train)\n",
    "    print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.. Which model performs better on your in-sample data?\n",
    "**ANSWER: For in-sample data, the model with a max depth of 10 had the highest accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.818352</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.026217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.028090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.140449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.915730</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.134831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.878277</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.097378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_acc   val_acc  train_val_diff\n",
       "2          3   0.818352  0.792135        0.026217\n",
       "3          4   0.820225  0.792135        0.028090\n",
       "9         10   0.921348  0.780899        0.140449\n",
       "8          9   0.915730  0.780899        0.134831\n",
       "6          7   0.878277  0.780899        0.097378"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_all = []\n",
    "\n",
    "for x in range(1,20):\n",
    "\n",
    "    tree = DT(max_depth=x, random_state=666)\n",
    "    tree.fit(x_train, y_train)\n",
    "    \n",
    "    # evaluate on train\n",
    "    train_acc = tree.score(x_train, y_train)\n",
    "    \n",
    "    #evaluate on validate\n",
    "    val_acc = tree.score(x_validate, y_validate)\n",
    "    \n",
    "    # difference between train and validate\n",
    "    train_val_diff = abs(train_acc - val_acc)\n",
    "    \n",
    "    scores_all.append([x, train_acc, val_acc, train_val_diff])\n",
    "    \n",
    "scores_df = pd.DataFrame(scores_all, columns=['max_depth','train_acc','val_acc', 'train_val_diff'])\n",
    "scores_df.sort_values(by=['val_acc'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.. Which model performs best on your out-of-sample data, the validate set?\n",
    "**ANSWER: For the validate set, models with max_depth of 3 and 4 performed equally well. They had the highest accuracy and the smallest difference between train_accuracy and validate_accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeClassifier_depth_through_twenty(xtrain,ytrain,xvalidate,yvalidate):\n",
    "    scores_all = []\n",
    "\n",
    "    for x in range(1,20):\n",
    "\n",
    "        tree = DT(max_depth=x, random_state=666)\n",
    "        tree.fit(xtrain, ytrain)\n",
    "        \n",
    "        # evaluate on train\n",
    "        train_acc = tree.score(xtrain, ytrain)\n",
    "        \n",
    "        #evaluate on validate\n",
    "        val_acc = tree.score(xvalidate, yvalidate)\n",
    "        \n",
    "        # difference between train and validate\n",
    "        train_val_diff = abs(train_acc - val_acc)\n",
    "        \n",
    "        scores_all.append([x, train_acc, val_acc, train_val_diff])\n",
    "        \n",
    "    scores_df = pd.DataFrame(scores_all, columns=['max_depth','train_acc','val_acc', 'train_val_diff'])\n",
    "    return scores_df.sort_values(by=['val_acc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_val_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.818352</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.026217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.028090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.140449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.915730</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.134831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.878277</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.097378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_acc   val_acc  train_val_diff\n",
       "2          3   0.818352  0.792135        0.026217\n",
       "3          4   0.820225  0.792135        0.028090\n",
       "9         10   0.921348  0.780899        0.140449\n",
       "8          9   0.915730  0.780899        0.134831\n",
       "6          7   0.878277  0.780899        0.097378"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier_depth_through_twenty(x_train,y_train,x_validate,y_validate).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
